# 1.1 모니터링 시스템 기초

## Overview
모니터링 시스템의 핵심 개념과 관찰 가능성의 기본 원리를 학습합니다. 현대적인 시스템 모니터링에 필요한 기초 이론과 패턴을 다룹니다.

## 관찰 가능성의 3개 기둥

### 메트릭 (Metrics)
**정의**: 시간에 따른 수치 데이터의 집합으로, 시스템의 상태를 정량적으로 측정합니다.

**특징**:
- 낮은 저장 공간 요구사항
- 높은 압축률과 빠른 쿼리 성능
- 장기간 데이터 보존 가능
- 알림 및 자동화에 적합

**메트릭 유형**:
- **카운터 (Counter)**: 단조 증가하는 값 (요청 수, 에러 수)
- **게이지 (Gauge)**: 증가/감소 가능한 값 (CPU 사용률, 메모리 사용량)
- **히스토그램 (Histogram)**: 값의 분포 측정 (응답 시간 분포)
- **요약 (Summary)**: 백분위수 측정 (P95, P99 응답시간)

### 로그 (Logs)
**정의**: 시스템에서 발생하는 이벤트의 시간순 기록으로, 상세한 컨텍스트 정보를 제공합니다.

**특징**:
- 높은 저장 공간 요구사항
- 상세한 디버깅 정보 포함
- 구조화된/비구조화된 형태
- 실시간 분석 및 검색 가능

**로그 레벨**:
- **ERROR**: 시스템 오류 및 예외 상황
- **WARN**: 잠재적 문제 상황
- **INFO**: 일반적인 정보성 메시지
- **DEBUG**: 상세한 디버깅 정보

### 트레이스 (Traces)
**정의**: 분산 시스템에서 요청의 전체 여정을 추적하여 서비스 간 상호작용을 시각화합니다.

**구성 요소**:
- **Trace**: 하나의 요청에 대한 전체 여정
- **Span**: 개별 작업 단위 (마이크로서비스 호출, 데이터베이스 쿼리)
- **Context**: 트레이스 정보를 서비스 간 전달하는 메타데이터

**활용 사례**:
- 성능 병목 지점 식별
- 서비스 의존성 매핑
- 오류 전파 경로 추적
- 레이턴시 분석

## Push vs Pull 모니터링 모델

### Pull 모델 (Prometheus 방식)
**작동 원리**: 모니터링 서버가 주기적으로 대상 시스템에서 메트릭을 수집합니다.

**장점**:
- 중앙 집중식 구성 관리
- 대상 시스템의 가용성 모니터링 가능
- 스크래핑 실패 시 즉시 감지
- 백프레셔 제어 (수집 서버가 부하 조절)

**단점**:
- 네트워크 연결성 요구사항
- 방화벽 설정 복잡성
- 대규모 환경에서 스케일링 한계

### Push 모델 (StatsD, InfluxDB 방식)
**작동 원리**: 대상 시스템이 능동적으로 모니터링 서버로 메트릭을 전송합니다.

**장점**:
- 네트워크 제약 없음
- 이벤트 기반 실시간 전송
- 동적 환경에 적합
- 대규모 분산 시스템에 유리

**단점**:
- 메트릭 손실 가능성
- 백프레셔 처리 복잡성
- 중복 메트릭 전송 위험

## 시계열 데이터 개념 및 저장 패턴

### 시계열 데이터 특성
**정의**: 시간순으로 정렬된 데이터 포인트 시퀀스로, 각 포인트는 타임스탬프와 값을 포함합니다.

**특성**:
- **시간 기반 인덱싱**: 타임스탬프가 주요 인덱스
- **순차적 삽입**: 대부분 최신 데이터부터 추가
- **집계 쿼리**: 시간 범위별 통계 연산이 주요 쿼리 패턴
- **압축 친화적**: 유사한 값들의 연속으로 높은 압축률

### 저장 패턴

#### 시간 기반 샤딩
```
데이터 분할 예시:
2024-01-01 ~ 2024-01-31: shard_2024_01
2024-02-01 ~ 2024-02-28: shard_2024_02
```

**장점**: 오래된 데이터 삭제 용이, 시간 범위 쿼리 최적화
**단점**: 핫스팟 문제 (최신 데이터에 쓰기 집중)

#### 메트릭 기반 파티셔닝
```
메트릭별 분할:
cpu_usage_* → partition_cpu
memory_usage_* → partition_memory
network_* → partition_network
```

**장점**: 메트릭별 보존 정책 적용 가능, 쿼리 성능 향상
**단점**: 파티션 간 조인 쿼리 복잡성

### 다운샘플링 전략
**목적**: 장기 보존을 위한 데이터 압축 및 쿼리 성능 향상

**계층별 보존**:
- **원본 데이터**: 1초 해상도, 7일 보존
- **5분 집계**: 5분 해상도, 30일 보존  
- **1시간 집계**: 1시간 해상도, 1년 보존
- **1일 집계**: 1일 해상도, 5년 보존

## SLA, SLO, SLI 정의 및 실제 적용

### SLI (Service Level Indicator)
**정의**: 서비스 성능을 측정하는 구체적인 지표

**예시**:
- **가용성**: 성공한 요청 수 / 전체 요청 수 × 100
- **레이턴시**: 95%의 요청이 100ms 이내 응답
- **처리량**: 초당 처리 가능한 요청 수
- **오류율**: 전체 요청 중 오류 발생 비율

### SLO (Service Level Objective)
**정의**: SLI에 대한 목표값 설정

**SMART 원칙 적용**:
- **Specific**: 구체적인 측정 지표
- **Measurable**: 정량적으로 측정 가능
- **Achievable**: 현실적으로 달성 가능
- **Relevant**: 비즈니스 목표와 연관
- **Time-bound**: 시간 범위 명시

**예시**:
```
웹 애플리케이션 SLO:
- 가용성: 월간 99.9% 이상 (43분 이하 다운타임)
- 응답시간: 95%의 요청이 200ms 이내 응답
- 오류율: 월간 0.1% 이하
```

### SLA (Service Level Agreement)
**정의**: 고객과의 법적 계약에 명시된 서비스 수준 약속

**구성 요소**:
- **성능 목표**: SLO 기반의 보장 수준
- **측정 방법**: SLI 계산 방식 명시
- **위반 시 조치**: 보상, 크레딧 제공 등
- **예외 조건**: 불가항력, 유지보수 시간 제외

### 오류 예산 (Error Budget)
**개념**: SLO에서 허용하는 오류의 양을 예산으로 관리

**계산 예시**:
```
99.9% 가용성 SLO의 경우:
월간 오류 예산 = (100% - 99.9%) × 총 시간
                = 0.1% × 30일 × 24시간 × 60분
                = 43.2분
```

**활용**:
- **오류 예산 소진 시**: 새로운 기능 배포 중단, 안정성 개선 집중
- **오류 예산 여유 시**: 적극적인 기능 개발 및 배포
- **위험 균형**: 혁신과 안정성 간의 균형점 제공

## Best Practices

### 모니터링 설계 원칙
1. **계층별 모니터링**: 인프라 → 플랫폼 → 애플리케이션 → 비즈니스
2. **적절한 도구 선택**: 각 관찰 가능성 기둥별 최적 도구 활용
3. **점진적 구현**: 핵심 메트릭부터 시작하여 단계적 확장
4. **자동화 우선**: 수동 개입 최소화를 위한 자동화 구현

### 메트릭 설계 가이드라인
1. **의미있는 메트릭**: 비즈니스 목표와 연결된 지표 선택
2. **적절한 카디널리티**: 높은 카디널리티 메트릭 사용 주의
3. **일관된 명명**: 조직 전체 통일된 메트릭 명명 규칙
4. **라벨 활용**: 메트릭 차원 분석을 위한 적절한 라벨 설계

## Benefits and Challenges

### Benefits
- **조기 문제 감지**: 사용자 영향 전 시스템 이상 감지
- **데이터 기반 의사결정**: 정량적 데이터를 통한 객관적 판단
- **성능 최적화**: 병목 지점 식별 및 개선 방향 제시
- **비즈니스 가치 증명**: 시스템 안정성의 비즈니스 영향 측정

### Challenges
- **복잡성 관리**: 다양한 도구와 데이터 소스의 통합 복잡성
- **데이터 과부하**: 과도한 메트릭 수집으로 인한 정보 홍수
- **비용 관리**: 모니터링 인프라 운영 비용 증가
- **인력 및 전문성**: 모니터링 시스템 운영을 위한 전문 인력 필요